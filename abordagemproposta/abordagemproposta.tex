\chapter{Abordagem Proposta}\label{sec:abordagemproposta}
Neste capítulo é proposta uma abordagem para reconhecer emoções por meio de expressão facial e está dividido da seguinte forma. Na Seção \ref{sec:detect} descreve um módulo de detecção de face e recorte. Na Seção \ref{sec:preproc} aborda as operações de pré-processamento aplicadas na imagem. Na Seção \ref{sec:redeneu} apresenta o classificador de expressões faciais e por fim um resumo do capítulo na Seção \ref{sec:considfi}.

\section{Detecção de Face e Recorte}\label{sec:detect}
Este procedimento consiste na detecção de todas as faces de uma imagem por meio do algoritmo Viola Jones (consultar Seção \ref{sec:detecfacialviola}) gerando um conjunto de coordenadas para criar um retângulo sobre a localização da face. Vale ressaltar que esta atividade possui complexidade moderada, pois uma imagem contém vários objetos com diferentes geometrias, inclusive podendo assemelhar-se a uma face acarretando na geração de falsos positivos. Logo após a detecção de face é realizado o recorte utilizando o conjunto de coordenadas definida pela etapa anterior, tal atividade é valorosa para exclusão do \textit{background}. Desta forma, é enviado somente a face recortada para a etapa de pré-processamento reduzindo a complexidade do problema, pois não há necessidade do classificador aprender a separar o \textit{background} da face. Posteriormente ao recorte da face, a imagem original que deve está com uma face recortada é mantida para nova averiguação de recorte de face. Caso exista outras faces na imagem, este processo é repetido até não existir mais faces para recortar. Obviamente caso seja enviada uma imagem para a etapa de detecção e recorte que não contém uma face (e.g. imagem de um avião) o processo é automaticamente encerrado, pois se não há uma face para detectar, logo não há uma expressão facial emocional para reconhecer. 

\section{Pré-Processamento}\label{sec:preproc}
Uma face recortada é enviada pelo módulo de Detecção de Face e Recorte para a fase de Pré-processamento. Nesta etapa são aplicadas operações de pré-processamento que realçam características relevantes que diferenciam as expressões faciais com intuito de preparar a imagem para a classificação. Inicialmente, uma função de redimensionamento da imagem é chamada para transformar a imagem em uma escala de 60x60 \textit{pixels}, como a imagem é colorida, isto é, possui 3 canais denominados RGB (do inglês: Red, Green e Blue) a imagem resultante possui 10.800 características que pode ser calculada por \textit{Qtd_Caracteristica = N_Pixels_X * N_Pixels_Y * N_Canais}. 

O problema visualizado por esta proposta consiste em classificar emoções em qualquer ambiente. É sabido que pela variação de ambiente que há diferença na intensidade da luz, ocorrendo a perda de características importantes da face que diferenciam as emoções. Vale destacar que esta proposta é baseada principalmente em redes neurais de convolução que originalmente possui vários filtros de pré-processamento de imagem. Entretanto, a literatura tem mostrado que filtros clássicos aplicados antes da inserção de uma imagem na rede tem sido eficazes na eliminação de ruídos presentes na imagem, principalmente aqueles relacionados a iluminação e brilho. Assim, a imagem resultante ressaltará melhor os traços faciais, além da imagem transformada está com maior nitidez para a rede neural de convolução. Portanto, as técnicas de normalização de brilho e iluminação é parte da etapa de pré-processamento.   


\section{Rede Neural de Convolução}\label{sec:redeneu}
A rede neural de convolução é a parte central e mais importante desta abordagem em discussão. Por meio dela a imagem é processada enfatizando contornos, padrões, formas e características da imagem relevantes para a classificação. Além disso, funções são aplicadas para redução de dimensionalidade e normalização ocasionando que a rede não seja sensível a rotações, posições e escala da imagem. Tais aptidões são essenciais para um classificador de imagens que deve ser usado em cenários reais maximizando a generalização. Entretanto, um desempenho satisfatório da rede neural de convolução, assim como de qualquer algoritmo supervisionado de aprendizagem de máquina, está estritamente relacionado ao processo de treinamento e validação do modelo.    

\subsection{Treinamento}
O treinamento da rede neural de convolução é parte fundamental para o reconhecedor de emoção alcançar generalização satisfatória e adquirir aprendizado suficiente para funcionar em variados ambientes. Para isso, o treinamento é apoiado pela técnica de aumento de dados com intuito de maximizar a generalização do aprendizado durante o treinamento. O aumento de dados consiste na multiplicação das imagens em tempo dinâmico modificando um pouco a imagem e seu contexto alterando as imagens de treinamento aplicando zoom, rotações, blur, shear diferentes níveis de contraste e entre outros, resultando em maior aprendizado e generalização do modelo. 

\subsection{Extração de Caracteríticas e Classificação}
A rede neural de convolução recebe a imagem pré-processada de uma face para classificá-la estimando a probabilidade para cada emoção: neutralidade, raiva, felicidade, tristeza, desprezo, medo e surpresa, de acordo com as caraterísticas extraídas da imagem.  A extração de característica é um procedimento responsável em identificar as zonas da imagem que são mais relevantes para a separação do problema, isto é, classificar uma expressão facial (\textit{e.g} o sorriso humano é uma expressão facial indicadora para a emoção felicidade). A extração de característica está embutida na rede neural de convolução que consiste nas camadas operando sobre a imagem de entrada ressaltando todos os contornos. Algumas camadas de convolução são especialistas na extração dos padrões verticais, outras nos horizontais, até que um conjunto de características são extraídas para o softmax classificar estimando a probabilidade para cada emoção.

%contornos, bordas, linhas, horinzontais, verticais
%Produto de probabilidades Naive Bayes

\subsection{Computação embarcada e em nuvem}
Esta proposta visa fornecer soluções para reconhecimento de emoção que contempla dois tipos de computação: em nuvem e embarcada. Tais computações estão em alta na academia, indústria e mercado. A primeira pelo crescimento da internet havendo bilhões de dispositivos conectados e a evolução da infraestrutura com aumento considerável de recursos computacionais e velocidade de conexão. A segunda pela explosão de dispositivos embarcados presentes em nosso cotiano. Além disso, os dispositivos embarcados de hoje tem uma autonomia energética periódica, hardware semelhante a desktops, sistemas operacionais e sensores embutidos, formando um dispositivo independente e poderoso. Há no mercado smartphones e smartwatches com processadores octa-core e dual-core respectivamente, com a memória RAM chegando a 8GB, e até mesmo com placas de vídeos embutidas para aceleração de computação.        

A computação em nuvem hospedaria o melhor modelo gerado a partir das arquituras AlexNet, VGGNet, GoogLeNet e Residuais, considerando métricas de avaliação de desempenho como precisão, revocação e f1-score. Apesar de que o melhor modelo possa exigir elevada utilização de recursos computacionais por ser uma rede neural profunda, entende-se que um serviço em nuvem possuiria um hardware robusto capaz de suportar a demanda da rede neural de convolucão. Visto que estamos no boom da computação cognitiva, isto é, a capacidade de computadores pensarem como humanos. A ideia de ter um reconhecedor de emoções em um serviço em nuvem é para quaisquer aplicação, independente de qual linguagem de programação foi implementada ou em qual sistema operacional está sendo executada, enviar imagens via padrão REST com intuito de receber a classificação das imagens com as emoções detectadas.    

A computação embarcada consiste na rede neural de convolução baseada na arquitetura MobileNet funcionar nativamente em um dispositivo embarcado. Essa arquitetura foi projetada para consumir menos recursos computacionais com o compromisso de perder o mínimo de precisão, sendo ideal para dispositivos embarcados que dispõe de menos recursos computacionais. Inclusive podendo funcionar nativamente no sistema operacional Android que é amplamente usado por \textit{smartphones}, \textit{smartwatches} e \textit{tablets}. Além disso, a arquitetura MobileNet pode ser também embutida em placas de desenvolvimento como Raspberry, Nvidia Jetson, Drones e outras.  

Vale destacar que as maiores taxas de ocupação de recursos computacional de uma rede neural de convolução estão na fase de treinamento, isto é, durante a geração do modelo. E a fase de classificação exige menores taxas de ocupação de hardware, pois o principal procedimento que demanda recursos computacionais consiste em carregar o modelo na memória. Quando uma imagem é enviada para classificação, considerando que o modelo está carregado na memória, a rede neural opera sobre a imagem aplicando os pesos advindos do modelo. Diferentemente da fase de treinamento que exige muito processamento, pois é executado o algoritmo de otimização gradiente descendente para minimizar a função de perda realizando uma alta quantidade de cálculos vetoriais.   
     

\section{Resumo}\label{sec:considfi}
'%imagens gerais